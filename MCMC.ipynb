{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 150\u001b[0m\n\u001b[0;32m    147\u001b[0m partitions \u001b[38;5;241m=\u001b[39m metropolis_MCMC(observed_network, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Estimate Link Reliability\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m reliability \u001b[38;5;241m=\u001b[39m estimate_link_reliability(observed_network, partitions)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Print Results\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 10 Most Reliable Links:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 128\u001b[0m, in \u001b[0;36mestimate_link_reliability\u001b[1;34m(G, partitions)\u001b[0m\n\u001b[0;32m    126\u001b[0m gu, gv \u001b[38;5;241m=\u001b[39m P[u], P[v]\n\u001b[0;32m    127\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m([gu, gv]))\n\u001b[1;32m--> 128\u001b[0m lO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m partitions \u001b[38;5;28;01mif\u001b[39;00m p[u] \u001b[38;5;241m==\u001b[39m p[v])  \u001b[38;5;66;03m# Count partitions where u,v are together\u001b[39;00m\n\u001b[0;32m    129\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(partitions)\n\u001b[0;32m    130\u001b[0m reliability[(u, v)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (lO \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (r \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 128\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m gu, gv \u001b[38;5;241m=\u001b[39m P[u], P[v]\n\u001b[0;32m    127\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m([gu, gv]))\n\u001b[1;32m--> 128\u001b[0m lO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m partitions \u001b[38;5;28;01mif\u001b[39;00m p[u] \u001b[38;5;241m==\u001b[39m p[v])  \u001b[38;5;66;03m# Count partitions where u,v are together\u001b[39;00m\n\u001b[0;32m    129\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(partitions)\n\u001b[0;32m    130\u001b[0m reliability[(u, v)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (lO \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (r \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import random\n",
    "import math  # Import math module\n",
    "\n",
    "def generate_block_network(block_sizes, prob_matrix):\n",
    "    \"\"\"Generate a stochastic block model (SBM) network.\"\"\"\n",
    "    num_blocks = len(block_sizes)\n",
    "    num_nodes = sum(block_sizes)\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Assign blocks\n",
    "    node_labels = []\n",
    "    current_label = 0\n",
    "    for i, size in enumerate(block_sizes):\n",
    "        for _ in range(size):\n",
    "            G.add_node(current_label, block=i)\n",
    "            node_labels.append(current_label)\n",
    "            current_label += 1\n",
    "    \n",
    "    # Add edges based on probability matrix\n",
    "    start_idx = 0\n",
    "    for i in range(num_blocks):\n",
    "        end_idx = start_idx + block_sizes[i]\n",
    "        start_jdx = 0\n",
    "        for j in range(num_blocks):\n",
    "            end_jdx = start_jdx + block_sizes[j]\n",
    "            \n",
    "            for u in range(start_idx, end_idx):\n",
    "                for v in range(start_jdx, end_jdx):\n",
    "                    if u < v and np.random.rand() < prob_matrix[i][j]:\n",
    "                        G.add_edge(u, v)\n",
    "            \n",
    "            start_jdx = end_jdx\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    return G\n",
    "\n",
    "def modify_network(G, modification_fraction):\n",
    "    \"\"\"Randomly remove and add links to create the observed network A_O.\"\"\"\n",
    "    G_modified = G.copy()\n",
    "    edges = list(G.edges())\n",
    "    nodes = list(G.nodes())\n",
    "    num_to_modify = int(len(edges) * modification_fraction)\n",
    "    \n",
    "    removed_edges = []\n",
    "    added_edges = []\n",
    "    \n",
    "    # Remove edges\n",
    "    edges_to_remove = np.random.choice(len(edges), num_to_modify // 2, replace=False)\n",
    "    for idx in edges_to_remove:\n",
    "        removed_edges.append(edges[idx])\n",
    "        G_modified.remove_edge(*edges[idx])\n",
    "    \n",
    "    # Add edges\n",
    "    for _ in range(num_to_modify // 2):\n",
    "        u, v = np.random.choice(nodes, 2, replace=False)\n",
    "        if not G_modified.has_edge(u, v):\n",
    "            G_modified.add_edge(u, v)\n",
    "            added_edges.append((u, v))\n",
    "    \n",
    "    return G_modified, removed_edges, added_edges\n",
    "\n",
    "def initialize_partition(G):\n",
    "    \"\"\"Initialize random partitions (each node is its own group).\"\"\"\n",
    "    return {node: node for node in G.nodes()}  # Every node is its own group initially\n",
    "\n",
    "def calculate_H(P, G):\n",
    "    \"\"\"Compute H(P) based on partition P.\"\"\"\n",
    "    block_counts = {}\n",
    "    for node, group in P.items():\n",
    "        if group not in block_counts:\n",
    "            block_counts[group] = []\n",
    "        block_counts[group].append(node)\n",
    "\n",
    "    lO = {}  # Observed links between blocks\n",
    "    r = {}   # Possible links between blocks\n",
    "    \n",
    "    # Count links in the observed network\n",
    "    for u, v in G.edges():\n",
    "        gu, gv = P[u], P[v]\n",
    "        key = tuple(sorted([gu, gv]))\n",
    "        lO[key] = lO.get(key, 0) + 1\n",
    "    \n",
    "    # Compute rαβ (max possible links between groups)\n",
    "    for (g1, nodes1), (g2, nodes2) in combinations(block_counts.items(), 2):\n",
    "        key = tuple(sorted([g1, g2]))\n",
    "        r[key] = len(nodes1) * len(nodes2)\n",
    "    \n",
    "    # Compute H(P)\n",
    "    H = sum(math.log(float(r[key] + 1)) + math.log(math.comb(r[key], lO.get(key, 0)))\n",
    "            for key in r)\n",
    "    \n",
    "    return H\n",
    "\n",
    "def metropolis_MCMC(G, num_samples=5):\n",
    "    \"\"\"Run MCMC sampling to estimate the partition distribution.\"\"\"\n",
    "    P = initialize_partition(G)  # Initial partition\n",
    "    partitions = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        node = random.choice(list(G.nodes()))\n",
    "        new_group = random.choice(list(P.values()))  # Move node to a random group\n",
    "        \n",
    "        # Compute ΔH\n",
    "        old_H = calculate_H(P, G)\n",
    "        P[node] = new_group\n",
    "        new_H = calculate_H(P, G)\n",
    "        delta_H = new_H - old_H\n",
    "        \n",
    "        # Accept move with probability exp(-ΔH)\n",
    "        if delta_H > 0 and np.random.rand() >= np.exp(-delta_H):\n",
    "            P[node] = node  # Reject the move\n",
    "        \n",
    "        partitions.append(P.copy())\n",
    "    \n",
    "    return partitions\n",
    "\n",
    "def estimate_link_reliability(G, partitions):\n",
    "    \"\"\"Compute R_L(i,j) for each edge based on sampled partitions.\"\"\"\n",
    "    reliability = {edge: 0 for edge in G.edges()}\n",
    "    \n",
    "    for P in partitions:\n",
    "        for u, v in G.edges():\n",
    "            gu, gv = P[u], P[v]\n",
    "            key = tuple(sorted([gu, gv]))\n",
    "            lO = sum(1 for p in partitions if p[u] == p[v])  # Count partitions where u,v are together\n",
    "            r = len(partitions)\n",
    "            reliability[(u, v)] += (lO + 1) / (r + 2)\n",
    "    \n",
    "    # Normalize\n",
    "    for edge in reliability:\n",
    "        reliability[edge] /= len(partitions)\n",
    "    \n",
    "    return reliability\n",
    "\n",
    "# Generate True Network (A_T)\n",
    "block_sizes = [10, 10, 10]  # Three groups of 10 nodes each\n",
    "prob_matrix = [[0.8, 0.2, 0.1], [0.2, 0.7, 0.15], [0.1, 0.15, 0.9]]\n",
    "true_network = generate_block_network(block_sizes, prob_matrix)\n",
    "\n",
    "# Create Observed Network (A_O)\n",
    "observed_network, removed, added = modify_network(true_network, modification_fraction=0.2)\n",
    "\n",
    "# Run MCMC Sampling\n",
    "partitions = metropolis_MCMC(observed_network, num_samples=10000)\n",
    "\n",
    "# Estimate Link Reliability\n",
    "reliability = estimate_link_reliability(observed_network, partitions)\n",
    "\n",
    "# Print Results\n",
    "print(\"Top 10 Most Reliable Links:\")\n",
    "for edge, rl in sorted(reliability.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"Edge {edge}: Reliability {rl:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
